---
title: "Fast Easy Kubernetes Clusters with Kops"
author_profile: false
excerpt: "...but most importantly, cheap."
header:
  overlay_image: /assets/img/home-header.jpg
tags:
  - aws
  - kubernetes
  - k8s
  - kops
  - how-to
---
**NOTE:** This write-up is based on but does not take precedent over the [official documentation](https://kops.sigs.k8s.io/getting_started/aws/). My intention is to simplify these instructions for my own understanding. The kops version used was `1.23.2`.
## Prerequisites
* a linux environment to work from, (personal machine, VM, EC2)
* `kops`,`kubectl`, and the `aws cli` must be [installed](https://kops.sigs.k8s.io/install/)
It may be possible to install these with your respective package manager. The docs mention having an ssh key generated before cluster creation. I didn't see an ssh key used in any commands later but I did already have an `id_rsa` key in my `.ssh` folder.
## IAM
The instructions specify creating an IAM user for kops and then go on to have you configure the aws cli to defaut to that user. While it is closer to best practice, I don't want my aws cli configured to use the kops user as default. I configured the aws cli for my personal IAM user that already has sufficient privileges. To do this:
* [Create an access key for your IAM user.](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html#Using_CreateAccessKey)
* Run `aws configure` from the terminal, entering your new access key id and secret access key at the prompts. I use the us-west-2 region as the default because it is closest to me and json as the default output but both are preference.
    * Test the cli with :
    ```bash
    aws ec2 describe-availability-zones
    ```
    The output should show the availability zones for your default region in the `ZoneName` field. Take note.
## Configure DNS
My goal in this was to provision a cluster quickly and cheaply for labs/fun. I decided to to go with the gossip-based-dns option To avoid having to purchase a domain and provision route53 records I decided to go with the gossip-based-dns option. So there is no DNS configuration!
## Cluster State Bucket
Kops uses S3 to manage state. You can think of the bucket as the `etcd` of kops.
Create a bucket for state. The bucket name has to be unique for the region you choose. Note that when [creating a bucket](https://docs.aws.amazon.com/cli/latest/reference/s3api/create-bucket.html) outside the us-east-1 region you need the `create-bucket-configuration` option:
```bash
aws s3api create-bucket
--bucket <state-bucket-name> \
--region us-west-2 \
--create-bucket-configuration LocationConstraint=us-west-2
```
## Create OIDC Bucket
I'd never heard of [OIDC](https://openid.net/connect/) before this but I'll have to read more to understand how kops is using it here. I do know kops needs a bucket for it to work from.
```bash
aws s3api create-bucket
--bucket <oidc-bucket-name> \
--region us-west-2 \
--create-bucket-configuration LocationConstraint=us-west-2 \
--acl public-read
```
## Create a cluster
Kops will automatically use gossip for dns when it seeds `.k8s.local` at the end of the cluster name. Without the `--node-count` parameter the default is one master and one worker node. I haven't tried yet but it is possible to specify multiple comma separated zones for high availability. See the [documentation](https://kops.sigs.k8s.io/cli/kops_create_cluster/#options) for many other options! Some notable ones are `--target` to generate terraform/cloudformation templates, `--dry-run` and `--output` to specify the format of the output without changing state, and `--cloud-labels` to add tags to the created resources. Omitting the `--yes` option prevents the cluster from being immediately created. The example in the documentation does this to showcase the `kops edit` and `kops update` commands so just know those are there for you when you need to make changes to the cluster later.
```bash
kops create cluster \
--name=<cluster-name.k8s.local> \
--cloud=aws \
--zones=<aws-az>\
--state=s3://<state-bucket-name>
--discovery-store=s3://<oidc-bucket-name>/<cluster-name.k8s.local>/discovery
--node-count=<number-of-desired-nodes>
--yes
```
## Validate
Run the `kops validate` command to make sure the cluster goes up ok. 
```bash
kops validate cluster --wait 10m
```
I ran into a recurring error related to authorization the first time around that I fixed with:
```bash
kops export kubecfg --admin
```
The docs make it seem as if my kube config file should have been updated automatically so I'm not sure what happened there but after that I was able to run kubectl without issue from my machine. 
## Delete
When you're done just run `kops delete cluster <cluster-name> --yes` to remove the resources provisioned from the `create` command.
